---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently pursuing the B.S. degree in IntelliSense Engineering at Shanghai Jiao Tong University, School of Electronic Information and Electrical Engineering. I'm exploring the field of **Simultaneous Localization And Mapping(SLAM)** and **Visual Language Navigation(VLN)** in the Collaborative Localization Research Group which is led by Prof. Zou DanPing now.

Although I haven't decided on my final research direction yet, my interest is particularly piqued by the perception of agents, equipping a brain in a vat with senses. I believe this is the first step towards achieving embodied intelligence. I can't wait to explore the frontiers of human knowledge and bring ideas into real life. To fulfill this goal, I study subjects broadly, from hardware to software and from control to instrument, preparing myself to do more interesting and impressive work in the future.

# üìù Research Experience 
- *2024 - now* **IDSLAM**. Text-based Simultaneous Localization And Mapping(SLAM) has garnered widespread attention in recent years. I have observed that there are numerous texts with numbered information in the environment, such as house numbers and shelf tags, which can be referred to as IDs. IDs possess excellent properties which can enhance the robustness and accuracy of SLAM systems. Upon further research, Language-Vision Models were found to be closely related to the project and thus were incorporated into the research scope.
- *2023 - 2024* **Drone-Assisted Multi-Sensory Autonomous Driving System**. Considering that relying solely on onboard sensors limits the safety and efficiency of autonomous driving, introducing a multi-sensory system to perceive road conditions is an effective solution. We propose the Drone-Assisted Multi-Sensory Autonomous Driving System which consists of a vehicle perception system, a blind spot detection system, a drone control system, a drone perception system, and a driving decision system. The supervisor of this project is Yanbo Liu, Shanghai Jiao Tong University. I am a co-first author of our paper, which has been accepted for presentation at SAECCE2024, scheduled for November. Additionally, it is awarded as an outstanding paper and has been recommended for publication in the Selected Papers Collection.

# üéñ Honors and Awards
- *2024* Mathematical Contest In Modeling, the Meritorious Winner. 
- *2023* China-U.S. Young Maker Competition Final, the First Prize of Main Track & the Intel Excellence Award.
- *2023* Contemporary Undergraduate Mathematical Contest in Modeling, the Second Prize in Shanghai.
- *2023* TI Cup National Undergraduate Electronics Design Contest, the Second Prize in Shanghai.

# üìñ Educations
- *2022 - now* **Shanghai Jiao Tong University**, School of Electronic Information and Electrical Engineering. MAJOR: IntelliSense Engineering; MINOR: Economics.
